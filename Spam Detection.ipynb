{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9255825,"sourceType":"datasetVersion","datasetId":5599950}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-27T11:22:29.850179Z","iopub.execute_input":"2024-08-27T11:22:29.850600Z","iopub.status.idle":"2024-08-27T11:22:30.316335Z","shell.execute_reply.started":"2024-08-27T11:22:29.850558Z","shell.execute_reply":"2024-08-27T11:22:30.315194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torch torch-geometric scikit-learn pandas tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T11:22:33.817607Z","iopub.execute_input":"2024-08-27T11:22:33.818446Z","iopub.status.idle":"2024-08-27T11:22:52.921558Z","shell.execute_reply.started":"2024-08-27T11:22:33.818378Z","shell.execute_reply":"2024-08-27T11:22:52.920131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data, Dataset\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GCNConv\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-08-27T11:22:52.923866Z","iopub.execute_input":"2024-08-27T11:22:52.924301Z","iopub.status.idle":"2024-08-27T11:23:02.257219Z","shell.execute_reply.started":"2024-08-27T11:22:52.924255Z","shell.execute_reply":"2024-08-27T11:23:02.255950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/spam-dataset/V2X_Data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-08-27T11:23:02.258598Z","iopub.execute_input":"2024-08-27T11:23:02.259259Z","iopub.status.idle":"2024-08-27T11:23:02.309091Z","shell.execute_reply.started":"2024-08-27T11:23:02.259213Z","shell.execute_reply":"2024-08-27T11:23:02.307746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"# Encode categorical variables\nle_source = LabelEncoder()\nle_dest = LabelEncoder()\nle_msg_type = LabelEncoder()\nle_priority = LabelEncoder()\nle_spam = LabelEncoder()\n\ndf['Source_encoded'] = le_source.fit_transform(df['Source Vehicle'])\ndf['Dest_encoded'] = le_dest.fit_transform(df['Destination Vehicle'])\ndf['MsgType_encoded'] = le_msg_type.fit_transform(df['Message Type'])\ndf['Priority_encoded'] = le_priority.fit_transform(df['Priority'])\ndf['Spam_encoded'] = le_spam.fit_transform(df['Spam'])\n\n# Step 2: Prepare BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-08-27T11:23:02.311225Z","iopub.execute_input":"2024-08-27T11:23:02.311599Z","iopub.status.idle":"2024-08-27T11:23:06.274515Z","shell.execute_reply.started":"2024-08-27T11:23:02.311559Z","shell.execute_reply":"2024-08-27T11:23:06.273284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.data import Dataset, Data\n\nclass CarNetworkDataset(Dataset):\n    def __init__(self, df, tokenizer, bert_model):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.bert_model = bert_model\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        if idx >= len(self.df):\n            raise IndexError(f\"Index {idx} out of range\")\n        row = self.df.iloc[idx]\n        \n        # Edge index for graph data\n        edge_index = torch.tensor([[row['Source_encoded']], [row['Dest_encoded']]], dtype=torch.long)\n        \n        # Graph features\n        x_graph = torch.tensor([row['MsgType_encoded'], row['Priority_encoded']], dtype=torch.float).unsqueeze(0)\n        \n        # Process text data with BERT\n        encoded_input = self.tokenizer(row['Message Content'], padding=True, truncation=True, return_tensors='pt')\n        with torch.no_grad():\n            bert_output = self.bert_model(**encoded_input)\n        text_features = bert_output.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n        \n        # Debugging print statements\n        print(f\"x_graph shape: {x_graph.shape}\")\n        print(f\"text_features shape: {text_features.shape}\")\n        \n        # Ensure x_graph and text_features are aligned\n        if x_graph.shape[0] != text_features.shape[0]:\n            print(f\"Expanding x_graph from shape {x_graph.shape} to {text_features.shape[0]}\")\n            x_graph = x_graph.expand(text_features.shape[0], -1)\n        \n        # Combine graph features and text features\n        x = torch.cat([x_graph, text_features], dim=1)\n        \n        # Target label\n        y = torch.tensor([row['Spam_encoded']], dtype=torch.long)\n        \n        return Data(x=x, edge_index=edge_index, y=y)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:31:58.160310Z","iopub.execute_input":"2024-08-27T12:31:58.160785Z","iopub.status.idle":"2024-08-27T12:31:58.174733Z","shell.execute_reply.started":"2024-08-27T12:31:58.160741Z","shell.execute_reply":"2024-08-27T12:31:58.173413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Create dataset\ndataset = CarNetworkDataset(df, tokenizer, bert_model)\n\n# Step 4: Split the dataset\ntrain_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:32:02.149487Z","iopub.execute_input":"2024-08-27T12:32:02.149916Z","iopub.status.idle":"2024-08-27T12:32:52.999950Z","shell.execute_reply.started":"2024-08-27T12:32:02.149876Z","shell.execute_reply":"2024-08-27T12:32:52.998698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass GCNModel(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(GCNModel, self).__init__()\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = self.fc(x)\n        return F.log_softmax(x, dim=1)\n\n# Step 6: Initialize the model and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNModel(input_dim=dataset[0].x.size(1), hidden_dim=64, output_dim=2).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:30:24.107224Z","iopub.execute_input":"2024-08-27T12:30:24.108522Z","iopub.status.idle":"2024-08-27T12:30:24.193372Z","shell.execute_reply.started":"2024-08-27T12:30:24.108456Z","shell.execute_reply":"2024-08-27T12:30:24.192089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:17:36.131158Z","iopub.execute_input":"2024-08-27T12:17:36.131590Z","iopub.status.idle":"2024-08-27T12:17:36.141560Z","shell.execute_reply.started":"2024-08-27T12:17:36.131547Z","shell.execute_reply":"2024-08-27T12:17:36.140080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport torch.nn.functional as F\n\ndef train():\n    model.train()\n    total_loss = 0\n    for data in train_loader:\n        data = data.to(device)\n        optimizer.zero_grad()\n        out = model(data.x, data.edge_index)\n        loss = F.nll_loss(out, data.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(train_loader)\n\ndef evaluate(loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            out = model(data.x, data.edge_index)\n            pred = out.argmax(dim=1)\n            all_preds.append(pred.cpu().numpy())\n            all_labels.append(data.y.cpu().numpy())\n\n    # Flatten the lists\n    all_preds = np.concatenate(all_preds)\n    all_labels = np.concatenate(all_labels)\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, average='binary')\n    recall = recall_score(all_labels, all_preds, average='binary')\n    f1 = f1_score(all_labels, all_preds, average='binary')\n    cm = confusion_matrix(all_labels, all_preds)\n\n    return accuracy, precision, recall, f1, cm\n\ntrain_acc, train_precision, train_recall, train_f1, train_cm = evaluate(train_loader)\ntest_acc, test_precision, test_recall, test_f1, test_cm = evaluate(test_loader)\n\nprint(f'Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}')\nprint(f'Train Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\nprint(f'Test Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\nprint(f'Train Confusion Matrix:\\n{train_cm}')\nprint(f'Test Confusion Matrix:\\n{test_cm}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:33:03.768935Z","iopub.execute_input":"2024-08-27T12:33:03.770743Z","iopub.status.idle":"2024-08-27T12:33:04.122489Z","shell.execute_reply.started":"2024-08-27T12:33:03.770650Z","shell.execute_reply":"2024-08-27T12:33:04.119989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Step 9: Run the training\nfor epoch in range(200):\n    loss = train()\n    train_acc = test(train_loader)\n    test_acc = test(test_loader)\n    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T12:30:30.397258Z","iopub.execute_input":"2024-08-27T12:30:30.397696Z","iopub.status.idle":"2024-08-27T12:30:30.672966Z","shell.execute_reply.started":"2024-08-27T12:30:30.397653Z","shell.execute_reply":"2024-08-27T12:30:30.671376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"x shape: {x.shape}\")\nprint(f\"text_features shape: {text_features.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T11:34:41.074442Z","iopub.execute_input":"2024-08-27T11:34:41.074902Z","iopub.status.idle":"2024-08-27T11:34:41.119362Z","shell.execute_reply.started":"2024-08-27T11:34:41.074859Z","shell.execute_reply":"2024-08-27T11:34:41.117749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            out = model(data.x, data.edge_index)\n            pred = out.argmax(dim=1)\n            all_preds.extend(pred.cpu().numpy())\n            all_labels.extend(data.y.cpu().numpy())\n    return np.array(all_preds), np.array(all_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T05:47:55.591778Z","iopub.execute_input":"2024-08-27T05:47:55.592667Z","iopub.status.idle":"2024-08-27T05:47:55.638995Z","shell.execute_reply.started":"2024-08-27T05:47:55.592604Z","shell.execute_reply":"2024-08-27T05:47:55.637852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 10: Final evaluation and metrics\nfinal_preds, final_labels = test(test_loader)\nfinal_acc = (final_preds == final_labels).mean()\nprint(f'Final Test Accuracy: {final_acc:.4f}')\n\n# Calculate precision, recall, and F1 score\nprecision, recall, f1, _ = precision_recall_fscore_support(final_labels, final_preds, average='binary')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\n\n# Create confusion matrix\ncm = confusion_matrix(final_labels, final_preds)\n\n# Visualize confusion matrix\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n\n# Visualize precision, recall, and F1 score\nmetrics = ['Precision', 'Recall', 'F1 Score']\nvalues = [precision, recall, f1]\n\nplt.figure(figsize=(10,7))\nsns.barplot(x=metrics, y=values)\nplt.title('Precision, Recall, and F1 Score')\nplt.ylim(0, 1)\nfor i, v in enumerate(values):\n    plt.text(i, v, f'{v:.2f}', ha='center', va='bottom')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-27T05:47:55.640320Z","iopub.execute_input":"2024-08-27T05:47:55.640715Z","iopub.status.idle":"2024-08-27T05:47:55.657000Z","shell.execute_reply.started":"2024-08-27T05:47:55.640674Z","shell.execute_reply":"2024-08-27T05:47:55.655676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-27T05:49:28.738901Z","iopub.execute_input":"2024-08-27T05:49:28.739357Z","iopub.status.idle":"2024-08-27T05:50:32.848448Z","shell.execute_reply.started":"2024-08-27T05:49:28.739314Z","shell.execute_reply":"2024-08-27T05:50:32.847105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Step 1: Load and preprocess the data\ndf = pd.read_csv('/kaggle/input/spam-dataset/V2X_Data.csv')\n\n# Encode categorical variables\nle_source = LabelEncoder()\nle_dest = LabelEncoder()\nle_msg_type = LabelEncoder()\nle_priority = LabelEncoder()\nle_spam = LabelEncoder()\n\ndf['Source_encoded'] = le_source.fit_transform(df['Source Vehicle'])\ndf['Dest_encoded'] = le_dest.fit_transform(df['Destination Vehicle'])\ndf['MsgType_encoded'] = le_msg_type.fit_transform(df['Message Type'])\ndf['Priority_encoded'] = le_priority.fit_transform(df['Priority'])\ndf['Spam_encoded'] = le_spam.fit_transform(df['Spam'])\n\n# Step 2: Prepare BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Step 3: Create graph data\nedge_index = torch.tensor([df['Source_encoded'].tolist(), df['Dest_encoded'].tolist()], dtype=torch.long)\nx = torch.tensor(df[['MsgType_encoded', 'Priority_encoded']].values, dtype=torch.float)\n\n# Process text data with BERT\nencoded_input = tokenizer(df['Message Content'].tolist(), padding=True, truncation=True, return_tensors='pt')\nwith torch.no_grad():\n    bert_output = bert_model(**encoded_input)\ntext_features = bert_output.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n\n# Combine graph features and text features\nx = torch.cat([x, text_features], dim=1)\n\ny = torch.tensor(df['Spam_encoded'].values, dtype=torch.long)\n\n# Create PyTorch Geometric Data object\ndata = Data(x=x, edge_index=edge_index, y=y)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T06:11:38.866131Z","iopub.execute_input":"2024-08-27T06:11:38.866563Z","iopub.status.idle":"2024-08-27T06:12:08.320222Z","shell.execute_reply.started":"2024-08-27T06:11:38.866523Z","shell.execute_reply":"2024-08-27T06:12:08.319184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Step 4: Define the Graph CNN model\nclass GCNModel(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(GCNModel, self).__init__()\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = self.fc(x)\n        return F.log_softmax(x, dim=1)\n\n# Step 5: Train-test split\ntrain_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\ntest_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\ntrain_indices, test_indices = train_test_split(range(data.num_nodes), test_size=0.2, random_state=42)\ntrain_mask[train_indices] = True\ntest_mask[test_indices] = True\n\ndata.train_mask = train_mask\ndata.test_mask = test_mask\n\n# Step 6: Initialize the model and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNModel(input_dim=x.size(1), hidden_dim=64, output_dim=2).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ndata = data.to(device)\n\n# Step 7: Training loop\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n# Step 8: Testing\ndef test():\n    model.eval()\n    with torch.no_grad():\n        out = model(data.x, data.edge_index)\n        pred = out.argmax(dim=1)\n        correct = pred[data.test_mask] == data.y[data.test_mask]\n        acc = int(correct.sum()) / int(data.test_mask.sum())\n    return acc\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T06:18:47.744431Z","iopub.execute_input":"2024-08-27T06:18:47.744925Z","iopub.status.idle":"2024-08-27T06:18:47.772218Z","shell.execute_reply.started":"2024-08-27T06:18:47.744879Z","shell.execute_reply":"2024-08-27T06:18:47.770605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 9: Run the training\nfor epoch in range(200):\n    loss = train()\n    if epoch % 10 == 0:\n        acc = test()\n        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')\n\n# Step 10: Final evaluation\nfinal_acc = test()\nprint(f'Final Test Accuracy: {final_acc:.4f}')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T06:18:54.736222Z","iopub.execute_input":"2024-08-27T06:18:54.736699Z","iopub.status.idle":"2024-08-27T06:18:56.631393Z","shell.execute_reply.started":"2024-08-27T06:18:54.736656Z","shell.execute_reply":"2024-08-27T06:18:56.630147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    out = model(data.x, data.edge_index)\n    pred = out.argmax(dim=1)\n    correct = data.y[data.test_mask]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T06:21:10.285984Z","iopub.execute_input":"2024-08-27T06:21:10.286428Z","iopub.status.idle":"2024-08-27T06:21:10.300874Z","shell.execute_reply.started":"2024-08-27T06:21:10.286387Z","shell.execute_reply":"2024-08-27T06:21:10.299491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred\ncorrect","metadata":{"execution":{"iopub.status.busy":"2024-08-27T06:21:14.597108Z","iopub.execute_input":"2024-08-27T06:21:14.597550Z","iopub.status.idle":"2024-08-27T06:21:14.608881Z","shell.execute_reply.started":"2024-08-27T06:21:14.597506Z","shell.execute_reply":"2024-08-27T06:21:14.607345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T06:09:45.110326Z","iopub.execute_input":"2024-08-27T06:09:45.111735Z","iopub.status.idle":"2024-08-27T06:09:45.118104Z","shell.execute_reply.started":"2024-08-27T06:09:45.111677Z","shell.execute_reply":"2024-08-27T06:09:45.116574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(new_data):\n    model.eval()\n    with torch.no_grad():\n        out = model(new_data.x, new_data.edge_index)\n        pred = out.argmax(dim=1)\n    return pred\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T06:09:53.826281Z","iopub.execute_input":"2024-08-27T06:09:53.826761Z","iopub.status.idle":"2024-08-27T06:09:53.833762Z","shell.execute_reply.started":"2024-08-27T06:09:53.826715Z","shell.execute_reply":"2024-08-27T06:09:53.832157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Step 1: Load and preprocess the data\n#df = pd.read_csv('car_network_data.csv')\n\n# Encode categorical variables\nle_source = LabelEncoder()\nle_dest = LabelEncoder()\nle_msg_type = LabelEncoder()\nle_priority = LabelEncoder()\nle_spam = LabelEncoder()\n\ndf['Source_encoded'] = le_source.fit_transform(df['Source Vehicle'])\ndf['Dest_encoded'] = le_dest.fit_transform(df['Destination Vehicle'])\ndf['MsgType_encoded'] = le_msg_type.fit_transform(df['Message Type'])\ndf['Priority_encoded'] = le_priority.fit_transform(df['Priority'])\ndf['Spam_encoded'] = le_spam.fit_transform(df['Spam'])\n\n# Step 2: Prepare BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Step 3: Create graph data\nedge_index = torch.tensor([df['Source_encoded'].tolist(), df['Dest_encoded'].tolist()], dtype=torch.long)\nx = torch.tensor(df[['MsgType_encoded', 'Priority_encoded']].values, dtype=torch.float)\n\n# Process text data with BERT\nencoded_input = tokenizer(df['Message Content'].tolist(), padding=True, truncation=True, return_tensors='pt')\nwith torch.no_grad():\n    bert_output = bert_model(**encoded_input)\ntext_features = bert_output.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n\n# Combine graph features and text features\nx = torch.cat([x, text_features], dim=1)\n\ny = torch.tensor(df['Spam_encoded'].values, dtype=torch.long)\n\n# Create PyTorch Geometric Data object\ndata = Data(x=x, edge_index=edge_index, y=y)\n\n# Step 4: Split the data\nnum_nodes = data.num_nodes\nnode_indices = list(range(num_nodes))\ntrain_indices, test_indices = train_test_split(node_indices, test_size=0.2, random_state=42)\n\ndata.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\ndata.train_mask[train_indices] = True\ndata.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\ndata.test_mask[test_indices] = True\n\n# Step 5: Define the Graph CNN model\nclass GCNModel(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(GCNModel, self).__init__()\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x, edge_index):\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n        x = self.fc(x)\n        return F.log_softmax(x, dim=1)\n\n# Step 6: Initialize the model and optimizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCNModel(input_dim=data.x.size(1), hidden_dim=64, output_dim=2).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ndata = data.to(device)\n\n# Step 7: Training loop\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\n# Step 8: Testing\ndef test():\n    model.eval()\n    with torch.no_grad():\n        out = model(data.x, data.edge_index)\n        pred = out.argmax(dim=1)\n        train_correct = pred[data.train_mask] == data.y[data.train_mask]\n        train_acc = int(train_correct.sum()) / int(data.train_mask.sum())\n        test_correct = pred[data.test_mask] == data.y[data.test_mask]\n        test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n    return train_acc, test_acc, pred[data.test_mask], data.y[data.test_mask]\n\n# Step 9: Run the training\nfor epoch in range(200):\n    loss = train()\n    train_acc, test_acc, _, _ = test()\n    if epoch % 10 == 0:\n        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n\n# Step 10: Final evaluation and metrics\n_, _, final_preds, final_labels = test()\nfinal_preds = final_preds.cpu().numpy()\nfinal_labels = final_labels.cpu().numpy()\n\nprecision, recall, f1, _ = precision_recall_fscore_support(final_labels, final_preds, average='binary')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\n\n# Create confusion matrix\ncm = confusion_matrix(final_labels, final_preds)\n\n# Visualize confusion matrix\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n\n# Visualize precision, recall, and F1 score\nmetrics = ['Precision', 'Recall', 'F1 Score']\nvalues = [precision, recall, f1]\n\nplt.figure(figsize=(10,7))\nsns.barplot(x=metrics, y=values)\nplt.title('Precision, Recall, and F1 Score')\nplt.ylim(0, 1)\nfor i, v in enumerate(values):\n    plt.text(i, v, f'{v:.2f}', ha='center', va='bottom')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-27T07:33:43.195507Z","iopub.execute_input":"2024-08-27T07:33:43.195965Z","iopub.status.idle":"2024-08-27T07:34:13.598825Z","shell.execute_reply.started":"2024-08-27T07:33:43.195923Z","shell.execute_reply":"2024-08-27T07:34:13.597705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}